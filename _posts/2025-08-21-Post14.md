---
title: Time Series > ARCH, GARCH
date: 2025-08-21 #HH:MM:SS +/-TTTT
categories: [Econometrics, Time Series]
tags: [econometrics, time series, arima]     # TAG names should always be lowercase
author: <author_id>                     # for single entry
description: Volatility Analysis
toc: true
math: true
mermaid: true
comments: true
---

**Note**
- "Stationary" means "Weak Stationary" in this post unless otherwise stated.
- Weak Staiontionary $\iff$ Ergodic for 2nd momenets. (It is known)
- If $\sum_{j=0}^{\infty} \lvert \gamma_j \rvert < \infty$, then $y_t$ is ergodic for 1st moments. (It is known)

Unlike in the [ARIMA post](https://jkang918.github.io/posts/Post12/), here in this post, we are focusing on cases where the error terms are **NOT** **white noise**.

Error term(s) is said to follow **white noise** if,

$$
E[\varepsilon_t] = 0
$$

$$
\mathrm{Var}(\varepsilon_t) = \sigma^2
$$

$$
\mathrm{Cov}(\varepsilon_t, \varepsilon_\tau) = 0, \text{ where } t \neq \tau
$$



## Background: Analysis of Volatility

In financial time series, volatility (= Risk) itself is time varying; for better time series forecasting, also to analyze the varying volatility itself, analysis of volatility is important.

In other words, we are focusing on cases where the error terms are not white noise anymore. $\sigma$ is time varying now.

Time varying property of volatility can be described as follow:

$$
P(|y_t| >c) > P(|y_{t-1}| >c), \; \forall c \in \mathbb{R}
$$
 
If $\\{ y_t \\}_{t=0}^T$ is stationary and normal $\Rightarrow$ 

$$
P(|y_t| >c) > P(|y_\{t-1\}| >c), \; \forall c \in \mathbb{R}
$$

i.e., 

$$
\sqrt{\mathrm{Var}(y_t| y_\{t-1\}, \cdots , y_1)} > \sqrt{\mathrm{Var}(y_{t-1}|y_{t-2}, \cdots , y_1)}
$$


Volatility stacks up; so it increases over time.

With this being said, we can formulate the volatility forecasting as follows:

$$
\sigma_{t|{t-1}, \; \cdots , \; 1} = f(y_{t-1}, \; \cdots , \; \sigma_{\{t-1\}|\{t-2\}}, \cdots)
$$

As you can see, the volatility is modeled as "conditional standard deviation" and it is time varying. This presents new challenge not covered in ARIMA modeling that is **"conditional heteroskedasticity"**.

Volatility modeling in general can be represented as follow:

$$
\left\{
\begin{aligned}
y_t &= \varepsilon_t 
      + f(y_{t-1}, y_{t-2}, \ldots, y_{t-p})
      + g(\varepsilon_{t-1}, \varepsilon_{t-2}, \ldots, \varepsilon_{t-p}) \\[6pt]
\sigma_t^2 &= f(\varepsilon_{t-1}^2, \varepsilon_{t-2}^2, \ldots, \varepsilon_{t-s}^2) + u_t
\end{aligned}
\right.
$$

$f$ and $g$ are link functions. There are three commonly used models for volatility analysis.

- **EWMA** (conditional heteroskedasticity not considered)  
- **ARCH**  
- **GARCH**

Before moving onto each model, let's quickly check how to compute **historical volaility** from a given sample period.

$$
\sigma_T = \hat{\sigma}_t \sqrt{n}, 
\quad \text{s.t.} \quad
\hat{\sigma}_t^2 = \frac{1}{n}\sum_{t=T-n}^{T-1}(y_t - \bar{y})^2
$$

- $\bar{y}$ : sample mean of the time series  
- Note. square root of time rule applied under i.i.d. assumption

## EWMA (Exponentially Weighted Moving Average)

$$
\text{EWMA} 
= \frac{y_{t-1}^2 + \lambda y_{t-2}^2 + \lambda^2 y_{t-3}^2 + \cdots + \lambda^{n-1}y_{t-n}^2}
{1 + \lambda + \lambda^2 + \cdots + \lambda^{n-1}}, 
\quad 0 < \lambda < 1
$$

As $n \to \infty$,

$$
\text{EWMA} = (1-\lambda)\sum_{i=1}^{\infty} \lambda^{i-1} y_{t-i}^2
$$

where

$$
(1-\lambda) = (1 + \lambda + \lambda^2 + \cdots)^{-1}
$$

Use EWMA as a proxy for conditiaonl variance at time $t$.

**Problem:** Conditional heteroskedasticity is not factored in.  


**※ Conditional Heteroskedasticity**

- Recall weak stationarity properties:  
  1. $E[y_t] = \mu$  
  2. $\text{Var}(y_t) = \gamma_0 < \infty$ (constant)  
  3. $\text{Cov}(y_t, y_{t-j}) = \gamma_j < \infty$ (depends only on lag $j$)  

- In **daily time series data**, heteroskedasticity is often observed, negatively affecting the credibility of ARIMA coefficients.  
- In contrast, it is known that **yearly data** usually do not show heteroskedasticity problems.  

## ARCH (Autoregressive Conditional Heteroskedasticity)

### ARCH(q)

**(1) Mean equation**

$$
y_t = a_0 + (a_1 y_{t-1} + a_2 y_{t-2} + \; \cdots \; + a_q y_{t-q}) + \sigma_t \xi_t, \quad \xi_t \stackrel{i.i.d.}{\sim}\mathcal N(0,1)
$$

where

$$
\varepsilon_t = \sigma_t \xi_t, \quad \varepsilon_t|\Omega_{t-1} \sim \mathcal{N}(0, \sigma_t)
$$

s.t. $\Omega_{t-1}$: information set until $t-1$

**(2) Variance equation**

$$
\sigma_t^2 = \alpha_0 + \alpha_1 \varepsilon_{t-1}^2 + \alpha_2 \varepsilon_{t-2}^2 + \; \cdots \; + \alpha_q \varepsilon_{t-q}^2
$$

s.t.
$$\sigma^2 = E[\varepsilon_t^2 | \Omega_{t-1}]$$


First, take a look at **(1) Mean equation**, which is basically AR(q) model, we have already covered except for the error term. Now, the error term consists of two parts: 1. time dependent standard deviation (= heteroskedasticity) and 2. stochastic piece (= $\xi_t$).

Now take a look at **(2) Variance equation.** Variance follows an MA(q) process in past squared errors. So in a way we can say ARCH(q) models conditional heteroskedasticity in a way the volatility itself is estimated by MA(q).

Ok. So how do we actually estimate the coefficients?

1. Estimate the coefficients in the **(1) Mean equation** using estimation method we covered in AR models.
2. Estimate the coefficients in the **(2) Variance equation** but with observed values, **$\hat{\varepsilon_t} = y_t - \hat{y_t}$**.

For estimation method, MLE is used over OLS. Numerical methods are used in solving the optimization problme of MLE loss function.

With the estimated $\hat{\sigma_t}$ values, now we can obtain any $n$-period volatility and $n$-period average volatility.

**Hypothesis test** here, I will only go through what the null hypothesis is. The null hypothesis here is:

$$
H_0: \alpha_1 = \; \cdots \; = \alpha_p = 0, \qquad H_1: \sim H_0
$$

The test statisticis:

$$
LM = TR^2 \sim \chi^2(p)
$$

is known to follow the chi-square distribution. $T$ is the number of time period and $R^2$ is the R-squared from **(2) Variance equation**.


- Interpretation: **variance follows an AR(p) process in past squared errors**  
- Summary: mean equation = ARX/ARMA-X, variance equation = ARCH(p)

## GARCH (Generalized Autoregressive Conditional Heteroskedasticity)

### GARCH(p, q)

If we pick large q for ARCH(q), due to large degree of freedom estimation becomes inefficient. GARCH(p, q) is used to mitigate that problem.

The mean equation is same as ARCH(q). The changed part is the variance equation.

$$
\sigma_t^2 = \underbrace{\alpha_0 + \alpha_1 \varepsilon_{t-1}^2 + \alpha_2 \varepsilon_{t-2}^2 + \; \cdots \; + \alpha_q \varepsilon_{t-q}^2}_{\text{ARCH terms}} + \underbrace{\beta_1 \sigma_{t-1}^2 + \beta_2 \sigma_{t-2}^2 + \; \cdots \; + \beta_p \sigma_{t-p}^2}_{\text{GARCH terms}}
$$

Remark. In ARCH(q), the variance equation resembled MA(q). In GARCH(p, q), the variance equation resembles ARMA(p, q).

The estimation procedure is same as ARCH(q): First tackle the mean equation and then go for the variance equation, after which run the hypothesis testing. The technical processes are out of the scope of this post.

Before finishing up with this post, lets briefly take a look at the relationship between ARCH and GARCH. Remember that we have shown in our previous post that AR(1) = MA(∞). By the same token, similar relationship holds here.

**GARCH(1, 1)**

$$
\begin{align*}
& \sigma_t^2 = \alpha_0 + \alpha \varepsilon_{t-1}^2 + \beta \sigma_{t-1}^2 \\  
& (1 - \beta L) \sigma_t^2 = \alpha_0 + \alpha \varepsilon_{t-1}^2 \\
& \sigma_t^2 &= \frac{\alpha_0}{(1- \beta L)} + \frac{\alpha}{(1- \beta L)}\varepsilon_{t-1}^2 \\
& &=  \frac{\alpha_0}{(1- \beta L)} + \alpha \sum_{j=1}^\infty \beta^{j-1} \varepsilon_{t-j}^2
\end{align*}
$$

Hence, GARCH(1, 1) = ARCH(∞) 
